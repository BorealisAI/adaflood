# @package _global_

# to execute this experiment run:
# python train.py experiment=example

defaults:
  - override /callbacks: diffusion.yaml
  - override /diffuser: ddpm.yaml

# all parameters below will be merged with parameters from default configurations set above
# this allows you to overwrite only specified parameters

tags: ["base", "final"]
eval_tags: ["ddpm", "test"]

trainer:
  min_epochs: 100
  max_epochs: 10000

data:
  batch_size: 96

hydra:
  run:
    dir: ${paths.log_dir}/${task_name}/seed${seed}/d${model.net.d_model}_lr${model.optimizer.lr}_wd${model.optimizer.weight_decay}/${eval_tags[0]}_${eval_tags[1]}

base_ckpt_path: ${paths.output_dir}/checkpoints/best.ckpt


