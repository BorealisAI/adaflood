# @package _global_

# Copyright (c) 2024-present, Royal Bank of Canada.
# Copyright (c) 2021 ashleve
# All rights reserved.
#
# This source code is licensed under the license found in the
# LICENSE file in the root directory of this source tree.
#####################################################################################
# Code is based on the pytorch lightning hydra template
# from https://github.com/ashleve/lightning-hydra-template
#################################################################################### 


defaults:
  - _self_
  - data: cls_dataset
  - model: resnet18 # thp_mix intensity_free thp_mix_aux intensity_free_aux
  - callbacks: cls.yaml
  - logger: null # done - set logger here or use command line (e.g. `python train.py logger=tensorboard`)
  - trainer: default.yaml # done
  - paths: default.yaml # done
  - extras: default.yaml # done
  - hydra: default.yaml # done

  # experiment configs allow for version control of specific hyperparameters
  # e.g. best hyperparameters for given model and datamodule
  - experiment: null

  # config for hyperparameter optimization
  - hparams_search: null # tpp_optuna

  # optional local config for machine/user specific settings
  # it's optional since it doesn't need to exist and is excluded from version control
  - optional local: default.yaml

  # debugging config (enable through command line, e.g. `python train.py debug=default)
  - debug: null


task_name: ${data.datasets.dataset}_${model.net.name}_alpha${data.alpha}_imb${data.imb_factor}_${tags[0]}_${tags[1]}

tags: ["dev", "test"]

# passing checkpoint path is necessary for evaluation
ckpt_path: ${paths.ckpt_dir}/epoch_${ckpt_epoch}.ckpt
last_ckpt_path: ${paths.ckpt_dir}/last.ckpt
ckpt_epoch: null

# seed for random number generators in pytorch, numpy and python.random
seed: 1
